{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70300319-d206-43ce-b3bf-3da6b079f20f",
   "metadata": {
    "id": "70300319-d206-43ce-b3bf-3da6b079f20f"
   },
   "source": [
    "## 基于MindNLP+MusicGen生成自己的个性化音乐\n",
    "\n",
    "MusicGen是来自Meta AI的Jade Copet等人提出的基于单个语言模型（LM）的音乐生成模型，能够根据文本描述或音频提示生成高质量的音乐样本，相关研究成果参考论文《[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)》。\n",
    "\n",
    "MusicGen模型基于Transformer结构，可以分解为三个不同的阶段:\n",
    "1. 用户输入的文本描述作为输入传递给一个固定的文本编码器模型，以获得一系列隐形状态表示。\n",
    "2. 训练MusicGen解码器来预测离散的隐形状态音频token。\n",
    "3. 对这些音频token使用音频压缩模型（如EnCodec）进行解码，以恢复音频波形。\n",
    "\n",
    "MusicGen直接使用谷歌的[t5-base](https://huggingface.co/t5-base)及其权重作为文本编码器模型，并使用[EnCodec 32kHz](https://huggingface.co/facebook/encodec_32khz)及其权重作为音频压缩模型。MusicGen解码器是一个语言模型架构，针对音乐生成任务从零开始进行训练。\n",
    "\n",
    "\n",
    "MusicGen 模型的新颖之处在于音频代码的预测方式。传统上，每个码本都必须由一个单独的模型（即分层）或通过不断优化 Transformer 模型的输出（即上采样）进行预测。与传统方法不同，MusicGen采用单个stage的Transformer LM结合高效的token交织模式，取消了多层级的多个模型结构，例如分层或上采样，这使得MusicGen能够生成单声道和立体声的高质量音乐样本，同时提供更好的生成输出控制。MusicGen不仅能够生成符合文本描述的音乐，还能够通过旋律条件控制生成的音调结构。\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/sanchit-gandhi/codesnippets/blob/main/delay_pattern.png?raw=true\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "**Figure 1:** MusicGen使用的码本延迟模式，来源于 [MusicGen paper](https://arxiv.org/abs/2306.05284).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee39cc-654b-4f0e-b601-013e484c16f0",
   "metadata": {
    "id": "77ee39cc-654b-4f0e-b601-013e484c16f0"
   },
   "source": [
    "## 下载模型\n",
    "\n",
    "MusicGen提供了small、medium和big三种规格的[预训练权重文件](https://huggingface.co/models?search=facebook/musicgen-)，本次指南默认使用small规格的权重，生成的音频质量较低，但是生成的速度是最快的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c14a55229ebb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.4.10，如需更换mindspore版本，可更改下面 MINDSPORE_VERSION 变量\n",
    "!pip uninstall mindspore -y\n",
    "%env MINDSPORE_VERSION=2.4.10\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/${MINDSPORE_VERSION}/MindSpore/unified/x86_64/mindspore-${MINDSPORE_VERSION}-cp39-cp39-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f0a7475372292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前 mindspore 版本\n",
    "!pip show mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da478a7404c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 mindnlp 包\n",
    "!pip install -i https://pypi.mirrors.ustc.edu.cn/simple mindnlp==0.2.4 jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d87424-9f38-4658-ba47-2a465d52ad77",
   "metadata": {
    "id": "b0d87424-9f38-4658-ba47-2a465d52ad77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.669 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.transformers import MusicgenForConditionalGeneration\n",
    "\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1166e-1335-4555-9ec4-223d1fbcb547",
   "metadata": {
    "id": "f6e1166e-1335-4555-9ec4-223d1fbcb547"
   },
   "source": [
    "## 生成音乐\n",
    "\n",
    "MusicGen支持两种生成模式：贪心（greedy）和采样（sampling）。在实际执行过程中，采样模式得到的结果要显著优于贪心模式。因此我们默认启用采样模式，并且可以在调用`MusicgenForConditionalGeneration.generate`时设置`do_sample=True`来显式指定使用采样模式。\n",
    "\n",
    "### 无提示生成\n",
    "\n",
    "我们可以通过方法 `MusicgenForConditionalGeneration.get_unconditional_inputs` 获得网络的随机输入，然后使用 `.generate` 方法进行自回归生成，指定 `do_sample=True` 来启用采样模式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7708e8-e4f1-4ab8-b04a-19395d78dea2",
   "metadata": {
    "id": "fb7708e8-e4f1-4ab8-b04a-19395d78dea2"
   },
   "outputs": [],
   "source": [
    "unconditional_inputs = model.get_unconditional_inputs(num_samples=1)\n",
    "\n",
    "audio_values = model.generate(**unconditional_inputs, do_sample=True, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb74df-c194-4d2e-930a-12473b08a919",
   "metadata": {
    "id": "94cb74df-c194-4d2e-930a-12473b08a919"
   },
   "source": [
    "音频输出是格式是: a Torch tensor of shape `(batch_size, num_channels, sequence_length)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de58334-40f7-4924-addb-2d6ff34c0590",
   "metadata": {
    "id": "6de58334-40f7-4924-addb-2d6ff34c0590"
   },
   "source": [
    "使用第三方库`scipy`将输出的音频保存为`musicgen_out.wav` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04291f52-0a75-4ddb-9eff-e853d0f17288",
   "metadata": {
    "id": "04291f52-0a75-4ddb-9eff-e853d0f17288"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "scipy.io.wavfile.write(\"musicgen_out.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613d212314085564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# # 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "# Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ff5b2-c170-4079-93a4-a02acbdaeb39",
   "metadata": {
    "id": "e52ff5b2-c170-4079-93a4-a02acbdaeb39"
   },
   "source": [
    "参数 `max_new_tokens` 指定要生成 `token` 数。根据经验，可以使用 `EnCodec` 模型的帧速率计算出生成的音频样本的长度（以秒为单位）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75ad107-e19b-47f3-9cf1-5102ab4ae74a",
   "metadata": {
    "id": "d75ad107-e19b-47f3-9cf1-5102ab4ae74a"
   },
   "outputs": [],
   "source": [
    "# audio_length_in_s = 256 / model.config.audio_encoder.frame_rate\n",
    "\n",
    "# audio_length_in_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e999b-2595-4090-8e1a-acfaa42d2581",
   "metadata": {
    "id": "9a0e999b-2595-4090-8e1a-acfaa42d2581"
   },
   "source": [
    "### 文本提示生成\n",
    "\n",
    "首先基于文本提示，通过`AutoProcessor`对输入进行预处理。然后将预处理后的输入传递给 `.generate` 方法以生成文本条件音频样本。同样，我们通过设置“do_sample=True”来启用采样模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741428a-7368-4b01-88d3-8608786252f5",
   "metadata": {},
   "source": [
    "其中，`guidance_scale` 用于无分类器指导（CFG），设置条件对数之间的权重（从文本提示中预测）和无条件对数（从无条件或空文本中预测）。`guidance_scale`越高表示生成的模型与输入的文本更加紧密。通过设置`guidance_scale > 1`来启用 CFG。为获得最佳效果，使用`guidance_scale=3`（默认值）生成文本提示音频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fba4154-13f6-403a-958b-101d6eacfb6e",
   "metadata": {
    "id": "5fba4154-13f6-403a-958b-101d6eacfb6e"
   },
   "outputs": [],
   "source": [
    "from mindnlp.transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[\"80s pop track with bassy drums and synth\", \"90s rock song with loud guitars and heavy drums\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"ms\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161179f5-f2ea-498f-8b24-020791fcb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\"musicgen_out_text.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8574181bee9a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# # 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "# Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391b2a1-6376-4b69-b562-4388b731cf60",
   "metadata": {
    "id": "d391b2a1-6376-4b69-b562-4388b731cf60"
   },
   "source": [
    "### 音频提示生成\n",
    "\n",
    "`AutoProcessor`同样可以对用于音频预测的音频提示进行预处理。在以下示例中，我们首先加载音频文件，然后进行预处理，并将输入给到网络模型来进行音频生成。最后，我们将生成出来的音频文件保存为` musicgen_out_audio.wav `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46303f8e-2a6d-467e-815a-d72f445f102f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sanchit-gandhi/gtzan\", split=\"train\", streaming=True)\n",
    "sample = next(iter(dataset))[\"audio\"]\n",
    "\n",
    "# take the first half of the audio sample\n",
    "sample[\"array\"] = sample[\"array\"][: len(sample[\"array\"]) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a5c28a-f6c1-4ac8-ae08-6776a2b2c5b8",
   "metadata": {
    "id": "56a5c28a-f6c1-4ac8-ae08-6776a2b2c5b8"
   },
   "outputs": [],
   "source": [
    "# 使用音视频提示生成，耗时较久\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "\n",
    "inputs = processor(\n",
    "    audio=sample[\"array\"],\n",
    "    sampling_rate=sample[\"sampling_rate\"],\n",
    "    text=[\"80s blues track with groovy saxophone\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"ms\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0682165f-8715-4209-877d-29d0e1e8c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\"musicgen_out_audio.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d283b99a48d83447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# # 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "# Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
